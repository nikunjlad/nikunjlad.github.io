---
title: "Interpretability in Image Classification Techniques"
tagline: "This is my independent research trying to answer the question how does image classification models work and how can we interpret them."
website: "https://github.com/nikunjlad/Interpretability-in-Image-Classification-Techniques"
skills: ["PyTorch", "Python", "NumPy"]
---

<img src="/img/interpretable.png" alt="Interpretation" width="85%">

How do computer vision algorithms work internally? How can we interpret their inner workings? These are some of the questions 
which many researchers are trying to answer lately. While, there are various algorithms like ResNets, GoogleNet, VGGNet, DenseNets, etc and
many more CNN architectures that exist, we often don't know how do they work internally and what kind of intuition do these models build
in the intermediate layers before classifying a particular image. This work is an independent study I pursued under the guidance of Professor
[Nik Brown](https://www.linkedin.com/in/nikbearbrown/){:target="_blank"}, where I tried to interpret these models.  
Check it out [here](https://interpretability-in-image-classification-techniques.readthedocs.io/en/latest/){:target="_blank"}!